<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Python on YS&#39;s blog</title>
    <link>https://www.yusaito.com/blog/posts/tech/python/</link>
    <description>Recent content in Python on YS&#39;s blog</description>
    <image>
      <url>https://www.yusaito.com/blog/papermod-cover.png</url>
      <link>https://www.yusaito.com/blog/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Tue, 22 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://www.yusaito.com/blog/posts/tech/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Pandasでread_csvしたときに出現するUnnamed:0を消す方法</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/pandas-read-csv-unnamed-name/</link>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/pandas-read-csv-unnamed-name/</guid>
      <description>問題：Pandas で csv を読むと謎の Unnamed:0 というコラムが出現 解決策 その１ : pd.read_csv で index_col = 0 を指定 df = pd.read_csv(&amp;#39;test.csv&amp;#39;, index_col=0) その２ : そもそも保存するときに index を消す df = pd.to_csv(&amp;#39;test.csv&amp;#39;, index = False) pandas の中身 ちなみに Unnamed:0 はこの辺りで追加されているらしい。
# ref. https://github.com/pandas-dev/pandas/blob/ad190575aa75962d2d0eade2de81a5fe5a2e285b/pandas/tests/io/parser/test_mangle_dupes.py#L120-L140 @skip_pyarrow def test_mangled_unnamed_placeholders(all_parsers): # xref gh-13017 orig_key = &amp;#34;0&amp;#34; parser = all_parsers orig_value = [1, 2, 3] df = DataFrame({orig_key: orig_value}) # This test recursively updates `df`. for i in range(3): expected = DataFrame() for j in range(i + 1): col_name = &amp;#34;Unnamed: 0&amp;#34; + f&amp;#34;.</description>
    </item>
    
    <item>
      <title>Python : hashlibを使って、ハッシュ値を求める</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-hashlib/</link>
      <pubDate>Sun, 20 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-hashlib/</guid>
      <description>ハッシュ値を求める import hashlib file_name = &amp;#34;important_file.dat&amp;#34; # MD5 ハッシュを生成する hs = hashlib.md5(file_name.encode()).hexdigest() # SHA224 ハッシュを生成する hs = hashlib.sha224(file_name.encode()).hexdigest() 自走プログラマー~Python の先輩が教えるプロジェクト開発のベストプラクティス 120の中でファイル名からハッシュ値を求め、そのハッシュ値の頭 3 文字を中間ディレクトリにして、１つのディレクトリにファイルを集中させないという手法が紹介されていた。
例 file_name = &amp;#34;important_file.dat&amp;#34; hs = hashlib.md5(file_name.encode()).hexdigest() file_path = f&amp;#34;dir_name/{hs[:3]}/{file_name}&amp;#34; 参考  </description>
    </item>
    
    <item>
      <title>Pythonで並列処理 : MPIREの使い方</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-mpire-multiprocess/</link>
      <pubDate>Sat, 19 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-mpire-multiprocess/</guid>
      <description>Python では joblib や concurrent.futures などで簡単にマルチプロセスできるが、&amp;ldquo;MultiProcessing Is Really Easy&amp;quot;という名の MPIRE というライブラリを見つけたので備忘録として残しておく。この記事によると、特定の場合では joblib や concurrent.futures よりも性能が良いらしい。
MPIRE のインストール pip install mpire MPIRE の使い方 from mpire import WorkerPool def time_consuming_function(param): return None with WorkerPool(n_jobs=8) as pool: results = pool.map_unordered(time_consuming_function, interator, progress_bar=True) 参考  </description>
    </item>
    
    <item>
      <title>PythonとopenCVで並列化</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/opencv-setnumthreads-multithreading/</link>
      <pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/opencv-setnumthreads-multithreading/</guid>
      <description>openCV でマルチプロセス化しようとしてもシングルプロセスになっている問題に遭遇 Python で openCV を使った処理をマルチプロセス化してみたのだが、どうもシングルプロセスになってしまうという問題に遭遇した。
解決策：cv2.setNumThreads(0)＆マルチプロセスをやめる。 cv2.setNumThreads(0) を加えて、かつマルチスレッド化（例えば、concurrent.future.ThreadPoolExecuterなど）することで効率的に並列処理可能になることが分かった。 cv2.setNumThreads(0)有りでもconcurrent.future.ProcessPoolExecuterでは、正しくマルチプロセスされなかった。
以下テンプレート。
import cv2 from concurrent.futures import ThreadPoolExecutor cv2.setNumThreads(0) def task_using_cv2(param): do_some_process_using_cv2() return with ThreadPoolExecutor() as executor: results = list(executor.map(task_using_cv2, param)) 参考   </description>
    </item>
    
    <item>
      <title>joblibの使い方</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-joblib/</link>
      <pubDate>Tue, 15 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-joblib/</guid>
      <description>joblib には主な機能として、1) 時間がかかる処理のキャッシュ化, 2)並列処理, 3)圧縮書き出しと読み込み、がある。
joblib のインストール pip install joblib joblib の主な機能 時間がかかる処理のキャッシュ化 (Memory) 途中で止まってしまったら困る数分とか数時間とかかかる処理のキャッシュをとっておきたいときに使う。
from joblib import Memory cachedir = &amp;#39;cache_dir&amp;#39; mem = Memory(cachedir) square = mem.cache(heavy_task_func) b = do_time_consuming_func(a) 並列処理 (Parallel, delayed) デフォルトはマルチプロセスだが、マルチスレッドも選択可能。
マルチプロセス（デフォルト） from joblib import Parallel, delayed Parallel(n_jobs=-1)(delayed(task_func)(param) for param in iterator) マルチスレッド Parallel(n_jobs=-1, backend=&amp;#39;threading&amp;#39;)(delayed(task_func)(param) for param in iterator) オブジェクトの圧縮書き出し（永続化）と読み込み（dump, load） 書き出し（永続化） joblib.dump(object,file_path,compress=3) 読み込み object = joblib.load(file_path) 参考  </description>
    </item>
    
    <item>
      <title>Ryzen Threadripper 3970XとNVIDIA RTX 3090を使ってnumpy(Intel MKL and OpenBLAS)とcupyでベンチマーク</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/numpy-benchmark-ryzen-threadripper/</link>
      <pubDate>Mon, 28 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/numpy-benchmark-ryzen-threadripper/</guid>
      <description>numpy でベンチマーク # ファイル名: numpy_benchmark.py import os os.environ[&amp;#34;OPENBLAS_NUM_THREADS&amp;#34;] = &amp;#34;32&amp;#34; # import mkl # mkl.set_num_threads(32) import numpy as np import time from threadpoolctl import threadpool_info from pprint import pp pp(threadpool_info()) np.show_config() N_LOOP = 5 calc_eigh_time_list = [] calc_inv_time_list = [] calc_dot_time_list = [] calc_norm_time_list = [] for size in [5000, 10000, 20000]: print(f&amp;#34;size : {size}&amp;#34;) for i in range(3): np.random.seed(i) X = np.random.randn(size, size) t_start = time.time() np.linalg.eigh(X @ X.T) calc_eigh_time_list.</description>
    </item>
    
    <item>
      <title>Python : functools.partial 関数の引数を一部固定</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-functools-partial/</link>
      <pubDate>Sat, 26 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-functools-partial/</guid>
      <description>functools.partial は、関数の特定の引数を固定したい場合に使う 個人的に concurrent.futures の ProcessPoolExecuter や ThreadPoolExecuter の map を使うときに併用することが多い。
functools.partial の定義 # ref. https://docs.python.org/ja/3/library/functools.html#functools.partial def partial(func, /, *args, **keywords): def newfunc(*fargs, **fkeywords): newkeywords = {**keywords, **fkeywords} return func(*args, *fargs, **newkeywords) newfunc.func = func newfunc.args = args newfunc.keywords = keywords return newfunc 使い方：引数を固定する from functools import partial def product_xyz(x, y, z): return x * y * z # xとyの値を固定する product_z = partial(product_xyz, x=2, y=3) product_z(4) # 24 参考  </description>
    </item>
    
    <item>
      <title>PythonとOpenCVで画像リストから動画を作成</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/create-video-from-images-opencv/</link>
      <pubDate>Sat, 26 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/create-video-from-images-opencv/</guid>
      <description>openCV を使って画像リストから動画を作成する。 画像リストがあったときにそこから動画を生成するときに使う。
from pathlib import Path from typing import List import cv2 def list_file_paths(dir_path: str) -&amp;gt; List[str]: &amp;#34;&amp;#34;&amp;#34; List file paths in a directory. Parameters ---------- dir_path : str Path of the directory Returns ------- List[str] List of the file paths in the directory &amp;#34;&amp;#34;&amp;#34; return sorted([str(path) for path in Path(dir_path).rglob(&amp;#34;*&amp;#34;) if path.is_file()]) def create_mp4_video_from_image_path_list( output_video_path: str, image_path_list: List[str], fps: int, ) -&amp;gt; None: &amp;#34;&amp;#34;&amp;#34; Create mp4 video file from a image path list Parameters ---------- output_video_path : str Path of the output video image_path_list : List[str] Path of image file list fps : int fps (frames per second) &amp;#34;&amp;#34;&amp;#34; height, width, _ = cv2.</description>
    </item>
    
    <item>
      <title>Pathlibで相対パスを有効活用する</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/relative-path-with-pathlib/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/relative-path-with-pathlib/</guid>
      <description>自走プログラマー~Python の先輩が教えるプロジェクト開発のベストプラクティス 120を読んだのでその中で気になった「ファイルパスはプログラムからの相対パスで組み立てるという箇所は実践的でとても勉強になったのでメモしておく。
├──　run.py ├──　data ├── input.txt └── images みたいなディレクトリがある場合は
import csv from pathlib import Path current_dir = Path(__file__).parent image_path = current_dir / &amp;#34;data&amp;#34; / &amp;#34;images&amp;#34; inuput_path = current_dir / &amp;#34;input.txt&amp;#34; とすればよい。</description>
    </item>
    
    <item>
      <title>tqdmでターミナルの横幅を狭めるとバグる問題を解消する</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/tqdm-dynamic-ncols/</link>
      <pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/tqdm-dynamic-ncols/</guid>
      <description>問題 : tqdm を標準出力している状態でターミナルの横幅を狭めるとバグる 解決策 : dynamic_ncols=True にする 下記のように tqdm を定義すればよい（参考）
from functools import partial from tqdm import tqdm as std_tqdm tqdm = partial(std_tqdm, dynamic_ncols=True) 参考  </description>
    </item>
    
    <item>
      <title>loggerとprintとtqdmの併用</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/tqdm-logging-print/</link>
      <pubDate>Sun, 13 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/tqdm-logging-print/</guid>
      <description>logger と print と tqdm を併用する場合は以下のコードをコピペする。
import contextlib import logging import logging.handlers import sys from time import sleep from tqdm import tqdm from tqdm.contrib import DummyTqdmFile class TqdmLoggingHandler(logging.Handler): colors = {&amp;#34;INFO&amp;#34;: &amp;#34;\033[37m{}\033[0m&amp;#34;} def __init__(self, level=logging.NOTSET): super().__init__(level) def emit(self, record): try: record.msg = TqdmLoggingHandler.colors.get(record.levelname, &amp;#34;{}&amp;#34;).format( record.msg ) msg = self.format(record) tqdm.write(msg, file=sys.stderr) self.flush() except Exception: self.handleError(record) class CustomFormatter(logging.Formatter): grey = &amp;#34;\x1b[38;20m&amp;#34; green = &amp;#34;\x1b[32;20m&amp;#34; yellow = &amp;#34;\x1b[33;20m&amp;#34; red = &amp;#34;\x1b[31;20m&amp;#34; bold_red = &amp;#34;\x1b[31;1m&amp;#34; reset = &amp;#34;\x1b[0m&amp;#34; format = &amp;#34;[%(asctime)s] [%(levelname)s] [%(process)d] [%(name)s] [%(funcName)s] [%(lineno)d] %(message)s&amp;#34; FORMATS = { logging.</description>
    </item>
    
    <item>
      <title>Pythonでファイルリストからの並列処理</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/multiprocess-multithreading-utils/</link>
      <pubDate>Thu, 03 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/multiprocess-multithreading-utils/</guid>
      <description>ファイルのリストを受け取って何らかの並列処理をする。 from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor from functools import partial from pathlib import Path from typing import List def list_file_paths(dir_path: str) -&amp;gt; List[str]: &amp;#34;&amp;#34;&amp;#34; List file paths in a directory. Parameters ---------- dir_path : str Path of the directory Returns ------- List[str] List of the file paths in the directory &amp;#34;&amp;#34;&amp;#34; return sorted([str(path) for path in Path(dir_path).rglob(&amp;#34;*&amp;#34;) if path.is_file()]) def task(same_value, same_value2, diffent_values): return None def multiprocess_task(task, same_value, same_value2, diffent_values): with ProcessPoolExecutor() as executor: results = list(executor.</description>
    </item>
    
    <item>
      <title>Pythonでjpgからpngへ一括変換</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/image-convert-jpg-png-multiprocess/</link>
      <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/image-convert-jpg-png-multiprocess/</guid>
      <description>jpg から png への一括変換 (マルチプロセス) from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor from functools import partial from pathlib import Path from typing import List from PIL import Image, ImageFile ImageFile.LOAD_TRUNCATED_IMAGES = True def list_file_paths(dir_path: str) -&amp;gt; List[str]: &amp;#34;&amp;#34;&amp;#34; List file paths in a directory. Parameters ---------- dir_path : str Path of the directory Returns ------- List[str] List of the file paths in the directory &amp;#34;&amp;#34;&amp;#34; return sorted([str(path) for path in Path(dir_path).rglob(&amp;#34;*&amp;#34;) if path.</description>
    </item>
    
    <item>
      <title>Pathlibの使い方</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-pathlib/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-pathlib/</guid>
      <description>今までパス操作は、組み込みのosとglob, pathlibが便利そうだったので調べてみる。
基本操作 ファイル名取得 ディレクトリ名取得 from pathlib import Path path = Path(&amp;#34;./dir/filename.txt&amp;#34;)  ファイル名を取得 : path.name ファイル名拡張子抜き : path.stem ファイルの拡張子のみ : path.suffix ファイルのディレクトリを取得 : path.parents (list) パス連結 : / 演算子を使う（path.joinpath()） パスの存在確認：path.exists() ファイルかどうか確認 : path.is_file() ディレクトリかどうか確認 : path.is_dir() ディレクトリの作成 : path.mkdir(exist_ok=True, parents=True) ディレクトリの削除 : path.rmdir() ファイル/ディレクトリパス変更 : path.replace(tgt) ファイル/ディレクトリパス変更（末尾のみ）: path.rename(new_file_apth) 同じ階層に別名ファイルを作成 : path.with_name(&#39;file_new.txt&#39;).touch() 同じ階層に別拡張子ファイルを作成 : path.with_suffix(&#39;png&#39;).touch() 同じ階層のファイルとディレクトリ一覧を返す：path.iterdir() ファイルの存在ディレクトリのパスを取得：Path(__file__).parent  個人的によく使うモジュール ファイルを再帰的に探索  Pathlib の場合  # Pathlibの場合 from pathlib import Path from typing import List def list_file_paths(dir_path: str) -&amp;gt; List[str]: &amp;#34;&amp;#34;&amp;#34; List file paths in a directory.</description>
    </item>
    
    <item>
      <title>Python : Dataclassを試してみる</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/python-dataclass/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/python-dataclass/</guid>
      <description>Python3.7 から加わった Dataclass に関して全く知らなかったので参考煮上げた記事を読みながらメモ.
通常の class と Dataclass の比較 通常の class class Person: def __init__(self, age = 20, gender = &amp;#34;female&amp;#34;): self.gender = gender self.age = age Dataclass from dataclasses import dataclass @dataclass class DataclassPerson: gender: str = &amp;#34;female&amp;#34; age: int = 20 DataClass の利点  可読性が高まる。 型アノテーションができる。 asdict で（ネストされたものでも）辞書に変換可能  参考  </description>
    </item>
    
    <item>
      <title>エラーメモ：IOError: image file is truncated</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/ioerror-image-file-is-truncated/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/ioerror-image-file-is-truncated/</guid>
      <description>IOError: image file is truncated jpg で結構大きめの画像を Pillow で読み込むときに下記のエラーが出た。
IOError: image file is truncated 解決策 from PIL import ImageFile ImageFile.LOAD_TRUNCATED_IMAGES = True 参考  </description>
    </item>
    
    <item>
      <title>Python : itertoolsの使い方 -その２-</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-itertools-2/</link>
      <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-itertools-2/</guid>
      <description>product は便利そうだけど、starmap は一行別で生成したほうが分かりやすそう。
itertools.groupby 同じキーをもつような要素からなる イテレーターのグループに対して、キーとグループを返すようなイテレータを作成する。通常、イテレーターは同じキー関数でソート済みである必要がある。
使い方 for k, g in itertools.groupby(&amp;#39;AAAABBBCCDAABBB&amp;#39;): print(k) # --&amp;gt; A B C D A B for k, g in itertools.groupby(&amp;#39;AAAABBBCCD&amp;#39;): print(list(g)) # --&amp;gt; AAAA BBB CC D itertools.islice 要素を選択・スライスして返すイテレータを生成。
使い方 for n in itertools.islice(&amp;#39;ABCDEFG&amp;#39;, 2): print(n) # --&amp;gt; A B itertools.pairwise 隣同士をペアにしたイテレータを返す。
使い方 for n in itertools.pairwise(&amp;#39;ABCDEFG&amp;#39;): print(n) # --&amp;gt; AB BC CD DE EF FG itertools.permutations 特定の長さの順列を返す。
使い方 for n in itertools.permutations(&amp;#39;ABCD&amp;#39;, 2): print(n) # --&amp;gt; AB AC AD BA BC BD CA CB CD DA DB DC itertools.</description>
    </item>
    
    <item>
      <title>Python : itertoolsの使い方 -その１-</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-itertools-1/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-itertools-1/</guid>
      <description>Atcoder などを昔解いていたときに itertools 便利だなーと思いつつも使いこなせていなかったので総まとめ。
itertools の解説その１ itertools.accumulate 累積和を返すイテレータを作成できる。
使い方 for n in itertools.accumulate([1,2,3,4,5]): print(n) # --&amp;gt; 1 3 6 10 15 itertools.chain ２つのシーケンスを１つのシーケンスとして扱う。
使い方 for n in itertools.chain(&amp;#39;ABC&amp;#39;, &amp;#39;DEF&amp;#39;): print(n) # --&amp;gt; A B C D E F itertools.combinations 特定の長さの組み合わせを返す。出力は辞書式でソートされている。
使い方 for n in itertools.combinations(&amp;#39;ABCD&amp;#39;, 2): print(n) # --&amp;gt; AB AC AD BC BD CD itertools.combinations_with_replacement 特定の長さの組み合わせを返す。出力は辞書式でソートされている。同じ要素が複数回現れることを許容。
使い方 for n in itertools.combinations_with_replacement(&amp;#39;ABC&amp;#39;, 2): print(n) # --&amp;gt; AA AB AC BB BC CC itertools.</description>
    </item>
    
    <item>
      <title>Pandas.DataFrame/Series と numpy.ndarray と list の相互変換</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/pandas-dataframe-series-convert-numpy-list/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/pandas-dataframe-series-convert-numpy-list/</guid>
      <description>Pandas.DataFrame/Series と numpy.ndarray と list の相互変換 (複数の) list から pd.DataFrame へ変換 大きく２つの方法がある。
df = pd.DataFrame({&amp;#39;list_1&amp;#39;:list_1, &amp;#39;list_2&amp;#39;:list_2, &amp;#39;list_3&amp;#39;=list_3}) df = pd.DataFrame( data=zip(list_1, list_2, list_3), columns=[&amp;#34;list_1&amp;#34;, &amp;#34;list_2&amp;#34;, &amp;#34;list_3&amp;#34;], ) numpy.ndarray から pd.DataFrame へ変換 # numpy_array # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8]] df = pd.DataFrame(data=numpy_array,columns=[&amp;#39;col_1&amp;#39;,&amp;#39;col_2&amp;#39;,&amp;#39;col_3&amp;#39;]) # col_1 col_2 col_3 # 0 0.0 1.0 2.0 # 1 3.0 4.0 5.0 # 2 6.0 7.0 8.0 pd.</description>
    </item>
    
  </channel>
</rss>
