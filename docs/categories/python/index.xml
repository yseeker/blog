<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Python on YS&#39;s blog</title>
    <link>https://www.yusaito.com/blog/categories/python/</link>
    <description>Recent content in Python on YS&#39;s blog</description>
    <image>
      <url>https://www.yusaito.com/blog/papermod-cover.png</url>
      <link>https://www.yusaito.com/blog/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Fri, 18 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://www.yusaito.com/blog/categories/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ryzen Threadripper 3970XとNVIDIA RTX 3090を使ってnumpy(Intel MKL and OpenBLAS)とcupyでベンチマーク [追記：jaxでも計測した]</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/numpy-benchmark-ryzen-threadripper/</link>
      <pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/numpy-benchmark-ryzen-threadripper/</guid>
      <description>numpy でベンチマーク # ファイル名: numpy_benchmark.py import os os.environ[&amp;#34;OPENBLAS_NUM_THREADS&amp;#34;] = &amp;#34;32&amp;#34; # import mkl # mkl.set_num_threads(32) import numpy as np import time from threadpoolctl import threadpool_info from pprint import pp pp(threadpool_info()) np.show_config() N_LOOP = 5 calc_eigh_time_list = [] calc_inv_time_list = [] calc_dot_time_list = [] calc_norm_time_list = [] for size in [5000, 10000, 20000]: print(f&amp;#34;size : {size}&amp;#34;) for i in range(3): np.random.seed(i) X = np.random.randn(size, size) t_start = time.time() np.linalg.eigh(X @ X.T) calc_eigh_time_list.</description>
    </item>
    
    <item>
      <title>PythonとopenCVで並列化</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/opencv-setnumthreads-multithreading/</link>
      <pubDate>Thu, 17 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/opencv-setnumthreads-multithreading/</guid>
      <description>openCV でマルチプロセス化しようとしてもシングルプロセスになっている問題に遭遇 Python で openCV を使った処理をマルチプロセス化してみたのだが、どうもシングルプロセスになってしまうという問題に遭遇した。
解決策：cv2.setNumThreads(0)＆マルチプロセスをやめる。 cv2.setNumThreads(0) を加えて、かつマルチスレッド化（例えば、concurrent.future.ThreadPoolExecuterなど）することで効率的に並列処理可能になることが分かった。 cv2.setNumThreads(0)有りでもconcurrent.future.ProcessPoolExecuterでは、正しくマルチプロセスされなかった。
以下テンプレート。
import cv2 from concurrent.futures import ThreadPoolExecutor cv2.setNumThreads(0) def task_using_cv2(param): do_some_process_using_cv2() return with ThreadPoolExecutor() as executor: results = list(executor.map(task_using_cv2, param)) 参考   </description>
    </item>
    
    <item>
      <title>joblibの使い方</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-joblib/</link>
      <pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-joblib/</guid>
      <description>joblib には主な機能として、1) 時間がかかる処理のキャッシュ化, 2)並列処理, 3)圧縮書き出しと読み込み、がある。
joblib のインストール pip install joblib joblib の主な機能 時間がかかる処理のキャッシュ化 (Memory) 途中で止まってしまったら困る数分とか数時間とかかかる処理のキャッシュをとっておきたいときに使う。
from joblib import Memory cachedir = &amp;#39;cache_dir&amp;#39; mem = Memory(cachedir) square = mem.cache(heavy_task_func) b = do_time_consuming_func(a) 並列処理 (Parallel, delayed) デフォルトはマルチプロセスだが、マルチスレッドも選択可能。
マルチプロセス（デフォルト） from joblib import Parallel, delayed Parallel(n_jobs=-1)(delayed(task_func)(param) for param in iterator) マルチスレッド Parallel(n_jobs=-1, backend=&amp;#39;threading&amp;#39;)(delayed(task_func)(param) for param in iterator) オブジェクトの圧縮書き出し（永続化）と読み込み（dump, load） 書き出し（永続化） joblib.dump(object,file_path,compress=3) 読み込み object = joblib.load(file_path) 参考  </description>
    </item>
    
    <item>
      <title>Pandasでread_csvしたときに出現するUnnamed:0を消す方法</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/pandas-read-csv-unnamed-name/</link>
      <pubDate>Fri, 25 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/pandas-read-csv-unnamed-name/</guid>
      <description>問題：Pandas で csv を読むと謎の Unnamed:0 というコラムが出現 解決策 その１ : pd.read_csv で index_col = 0 を指定 df = pd.read_csv(&amp;#39;test.csv&amp;#39;, index_col=0) その２ : そもそも保存するときに index を消す df = pd.to_csv(&amp;#39;test.csv&amp;#39;, index = False) pandas の中身 ちなみに Unnamed:0 はこの辺りで追加されているらしい。
# ref. https://github.com/pandas-dev/pandas/blob/ad190575aa75962d2d0eade2de81a5fe5a2e285b/pandas/tests/io/parser/test_mangle_dupes.py#L120-L140 @skip_pyarrow def test_mangled_unnamed_placeholders(all_parsers): # xref gh-13017 orig_key = &amp;#34;0&amp;#34; parser = all_parsers orig_value = [1, 2, 3] df = DataFrame({orig_key: orig_value}) # This test recursively updates `df`. for i in range(3): expected = DataFrame() for j in range(i + 1): col_name = &amp;#34;Unnamed: 0&amp;#34; + f&amp;#34;.</description>
    </item>
    
    <item>
      <title>Python : functools.partial 関数の引数を一部固定</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/how-to-use-functools-partial/</link>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/how-to-use-functools-partial/</guid>
      <description>functools.partial は、関数の特定の引数を固定したい場合に使う 個人的に concurrent.futures の ProcessPoolExecuter や ThreadPoolExecuter の map を使うときに併用することが多い。
functools.partial の定義 # ref. https://docs.python.org/ja/3/library/functools.html#functools.partial def partial(func, /, *args, **keywords): def newfunc(*fargs, **fkeywords): newkeywords = {**keywords, **fkeywords} return func(*args, *fargs, **newkeywords) newfunc.func = func newfunc.args = args newfunc.keywords = keywords return newfunc 使い方：引数を固定する from functools import partial def product_xyz(x, y, z): return x * y * z # xとyの値を固定する product_z = partial(product_xyz, x=2, y=3) product_z(4) # 24 参考  </description>
    </item>
    
    <item>
      <title>Pathlibで相対パスを有効活用する</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/relative-path-with-pathlib/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/relative-path-with-pathlib/</guid>
      <description>自走プログラマー~Python の先輩が教えるプロジェクト開発のベストプラクティス 120を読んだのでその中で気になった「ファイルパスはプログラムからの相対パスで組み立てるという箇所は実践的でとても勉強になったのでメモしておく。
├──　run.py ├──　data ├── input.txt └── images みたいなディレクトリがある場合は
import csv from pathlib import Path current_dir = Path(__file__).parent image_path = current_dir / &amp;#34;data&amp;#34; / &amp;#34;images&amp;#34; inuput_path = current_dir / &amp;#34;input.txt&amp;#34; とすればよい。</description>
    </item>
    
    <item>
      <title>loggerとprintとtqdmの併用</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/tqdm-logging-print/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/tqdm-logging-print/</guid>
      <description>logger と print と tqdm を併用する場合は以下のコードをコピペする。tqdm の出力に色付けできる。
import contextlib import logging import logging.handlers import sys from time import sleep from tqdm import tqdm from tqdm.contrib import DummyTqdmFile class TqdmLoggingHandler(logging.Handler): colors = {&amp;#34;INFO&amp;#34;: &amp;#34;\033[37m{}\033[0m&amp;#34;} def __init__(self, level=logging.NOTSET): super().__init__(level) def emit(self, record): try: record.msg = TqdmLoggingHandler.colors.get(record.levelname, &amp;#34;{}&amp;#34;).format( record.msg ) msg = self.format(record) tqdm.write(msg, file=sys.stderr) self.flush() except Exception: self.handleError(record) class CustomFormatter(logging.Formatter): grey = &amp;#34;\x1b[38;20m&amp;#34; green = &amp;#34;\x1b[32;20m&amp;#34; yellow = &amp;#34;\x1b[33;20m&amp;#34; red = &amp;#34;\x1b[31;20m&amp;#34; bold_red = &amp;#34;\x1b[31;1m&amp;#34; reset = &amp;#34;\x1b[0m&amp;#34; format = &amp;#34;[%(asctime)s] [%(levelname)s] [%(process)d] [%(name)s] [%(funcName)s] [%(lineno)d] %(message)s&amp;#34; FORMATS = { logging.</description>
    </item>
    
    <item>
      <title>Pythonでファイルリストからの並列処理</title>
      <link>https://www.yusaito.com/blog/posts/tech/python/multiprocess-multithreading-utils/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.yusaito.com/blog/posts/tech/python/multiprocess-multithreading-utils/</guid>
      <description>ファイルのリストを受け取って何らかの並列処理をする。 from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor from functools import partial from pathlib import Path from typing import List def list_file_paths(dir_path: str) -&amp;gt; List[str]: &amp;#34;&amp;#34;&amp;#34; List file paths in a directory. Parameters ---------- dir_path : str Path of the directory Returns ------- List[str] List of the file paths in the directory &amp;#34;&amp;#34;&amp;#34; return sorted([str(path) for path in Path(dir_path).rglob(&amp;#34;*&amp;#34;) if path.is_file()]) def task(same_value, same_value2, diffent_values): return None def multiprocess_task(task, same_value, same_value2, diffent_values): with ProcessPoolExecutor() as executor: results = list(executor.</description>
    </item>
    
  </channel>
</rss>
